{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from _datetime import datetime\n",
    "import pytz\n",
    "from progressbar import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Google Drive Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-95b2450d87f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgd_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gdrive/My Drive/cs4487-machine-learning/course-project\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgd_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "gd_root = \"gdrive/My Drive/cs4487-machine-learning/course-project\"\n",
    "gd_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normal = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Training on CPU\n"
     ]
    }
   ],
   "source": [
    "#check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print(\"CUDA is not available. Training on CPU\")\n",
    "else:\n",
    "    print(\"CUDA is available. Training on GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dset.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_normal)\n",
    "trainloader = DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gd_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9fd0d82943b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{gd_root}/test_data/y_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gd_root' is not defined"
     ]
    }
   ],
   "source": [
    "testset = np.load(f\"{gd_root}/test_data/y_test.npy\").astype(np.uint8)\n",
    "testset = np.moveaxis(testset, -1, 2)\n",
    "testset = np.moveaxis(testset, 2, 1)\n",
    "testset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #定义优化器\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()   # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _,preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 *acc ))\n",
    "        return acc\n",
    "def train_model(model, optimizer, epochs=1, scheduler=None):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - model: A Pytorch Module giving the model to train.\n",
    "    - optimizer: An optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train\n",
    "    Returns: best model\n",
    "    '''\n",
    "    best_model_wts = None\n",
    "    best_acc = 0.0\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            model.train()   # set model to training mode\n",
    "            x = x.to(device, dtype=dtype)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch %d, loss=%.4f' % (e, loss.item()))\n",
    "        acc = check_accuracy(testloader, model)\n",
    "        if acc > best_acc:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_acc = acc\n",
    "    print('best_acc:',best_acc)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_orthonormal(shape):\n",
    "    # Orthonorm init code is taked from Lasagne\n",
    "    # https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.standard_normal(flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def get_activations(model, layer, X_batch):\n",
    "    intermediate_layer_model = Model(\n",
    "        inputs=model.get_input_at(0),\n",
    "        outputs=layer.get_output_at(0)\n",
    "    )\n",
    "    activations = intermediate_layer_model.predict(X_batch)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def LSUVinit(model, batch, verbose=True, margin=0.1, max_iter=10):\n",
    "    # only these layer classes considered for LSUV initialization; add more if needed\n",
    "    classes_to_consider = (Dense, Convolution2D)\n",
    "\n",
    "    needed_variance = 1.0\n",
    "\n",
    "    layers_inintialized = 0\n",
    "    for layer in model.layers:\n",
    "        if verbose:\n",
    "            print(layer.name)\n",
    "        if not isinstance(layer, classes_to_consider):\n",
    "            continue\n",
    "        # avoid small layers where activation variance close to zero, esp. for small batches\n",
    "        if np.prod(layer.get_output_shape_at(0)[1:]) < 32:\n",
    "            if verbose:\n",
    "                print(layer.name, 'too small')\n",
    "            continue\n",
    "        if verbose:\n",
    "            print('LSUV initializing', layer.name)\n",
    "\n",
    "        layers_inintialized += 1\n",
    "        weights_and_biases = layer.get_weights()\n",
    "        weights_and_biases[0] = svd_orthonormal(weights_and_biases[0].shape)\n",
    "        layer.set_weights(weights_and_biases)\n",
    "        activations = get_activations(model, layer, batch)\n",
    "        variance = np.var(activations)\n",
    "        iteration = 0\n",
    "        if verbose:\n",
    "            print(variance)\n",
    "        while abs(needed_variance - variance) > margin:\n",
    "            if np.abs(np.sqrt(variance)) < 1e-7:\n",
    "                # avoid zero division\n",
    "                break\n",
    "\n",
    "            weights_and_biases = layer.get_weights()\n",
    "            weights_and_biases[0] /= np.sqrt(variance) / np.sqrt(needed_variance)\n",
    "            layer.set_weights(weights_and_biases)\n",
    "            activations = get_activations(model, layer, batch)\n",
    "            variance = np.var(activations)\n",
    "\n",
    "            iteration += 1\n",
    "            if verbose:\n",
    "                print(variance)\n",
    "            if iteration >= max_iter:\n",
    "                break\n",
    "    if verbose:\n",
    "        print('LSUV: total layers initialized', layers_inintialized)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "conv2d_16\n",
      "LSUV initializing conv2d_16\n",
      "0.014633735\n",
      "1.0\n",
      "activation_18\n",
      "conv2d_17\n",
      "LSUV initializing conv2d_17\n",
      "0.05120702\n",
      "1.0000002\n",
      "activation_19\n",
      "conv2d_18\n",
      "LSUV initializing conv2d_18\n",
      "0.054358415\n",
      "1.0\n",
      "activation_20\n",
      "conv2d_19\n",
      "LSUV initializing conv2d_19\n",
      "0.02873595\n",
      "0.99999976\n",
      "activation_21\n",
      "conv2d_20\n",
      "LSUV initializing conv2d_20\n",
      "0.024307601\n",
      "1.0000001\n",
      "activation_22\n",
      "max_pooling2d_3\n",
      "dropout_5\n",
      "conv2d_21\n",
      "LSUV initializing conv2d_21\n",
      "0.016030274\n",
      "0.9999999\n",
      "activation_23\n",
      "conv2d_22\n",
      "LSUV initializing conv2d_22\n",
      "0.021735683\n",
      "1.0000001\n",
      "activation_24\n",
      "conv2d_23\n",
      "LSUV initializing conv2d_23\n",
      "0.018159432\n",
      "0.9999999\n",
      "activation_25\n",
      "conv2d_24\n",
      "LSUV initializing conv2d_24\n",
      "0.02422906\n",
      "0.9999999\n",
      "activation_26\n",
      "conv2d_25\n",
      "LSUV initializing conv2d_25\n",
      "0.018832816\n",
      "1.0000001\n",
      "activation_27\n",
      "max_pooling2d_4\n",
      "dropout_6\n",
      "conv2d_26\n",
      "LSUV initializing conv2d_26\n",
      "0.021022359\n",
      "1.0\n",
      "activation_28\n",
      "conv2d_27\n",
      "LSUV initializing conv2d_27\n",
      "0.011190941\n",
      "1.0\n",
      "activation_29\n",
      "conv2d_28\n",
      "LSUV initializing conv2d_28\n",
      "0.011638361\n",
      "0.9999999\n",
      "activation_30\n",
      "conv2d_29\n",
      "LSUV initializing conv2d_29\n",
      "0.011832624\n",
      "1.0000001\n",
      "activation_31\n",
      "conv2d_30\n",
      "LSUV initializing conv2d_30\n",
      "0.012013839\n",
      "0.9999998\n",
      "activation_32\n",
      "global_max_pooling2d_2\n",
      "dropout_7\n",
      "dense_3\n",
      "LSUV initializing dense_3\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalMaxPooling2D\n",
    "\n",
    "batch_size = 32 \n",
    "num_classes = 10\n",
    "epochs = 1600\n",
    "data_augmentation = True\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(48, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(ZeroPadding2D((1, 1)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "'''\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "'''\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "model = LSUVinit(model,x_train[:batch_size,:,:,:]) \n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph2', histogram_freq=0, write_graph=True, write_images=True)\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True, callbacks=[tbCallBack])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test), callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a0e16203a22d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcifar10_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloader_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar10_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dset' is not defined"
     ]
    }
   ],
   "source": [
    "cifar10_train = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_aug)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, shuffle=True)\n",
    "learning_rate = 1e-2\n",
    "resnet = ResNet18()\n",
    "optimizer_resnet = torch.optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "scheduler = lr_scheduler.StepLR(optimizer_resnet, step_size=15,gamma=0.1)\n",
    "best_resnet_v2 = train_model(resnet, optimizer_resnet,50, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "__all__ = ['Inception3', 'inception_v3']\n",
    "\n",
    "\n",
    "_InceptionOuputs = namedtuple('InceptionOuputs', ['logits', 'aux_logits'])\n",
    "\n",
    "\n",
    "def inception_v3(pretrained=False, progress=True, device='cpu', **kwargs):\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "    .. note::\n",
    "        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n",
    "            Default: *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    model = Inception3()\n",
    "    if pretrained:\n",
    "        script_dir = os.path.dirname(__file__)\n",
    "        state_dict = torch.load(script_dir + '/state_dicts/inception_v3.pt', map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "    ## CIFAR10: aux_logits True->False\n",
    "    def __init__(self, num_classes=10, aux_logits=False, transform_input=False):\n",
    "        super(Inception3, self).__init__()\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        \n",
    "        ## CIFAR10: stride 2->1, padding 0 -> 1\n",
    "        self.Conv2d_1a_3x3 = BasicConv2d(3, 192, kernel_size=3, stride=1, padding=1)\n",
    "#         self.Conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=3)\n",
    "#         self.Conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.Conv2d_3b_1x1 = BasicConv2d(64, 80, kernel_size=1)\n",
    "#         self.Conv2d_4a_3x3 = BasicConv2d(80, 192, kernel_size=3)\n",
    "        self.Mixed_5b = InceptionA(192, pool_features=32)\n",
    "        self.Mixed_5c = InceptionA(256, pool_features=64)\n",
    "        self.Mixed_5d = InceptionA(288, pool_features=64)\n",
    "        self.Mixed_6a = InceptionB(288)\n",
    "        self.Mixed_6b = InceptionC(768, channels_7x7=128)\n",
    "        self.Mixed_6c = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6d = InceptionC(768, channels_7x7=160)\n",
    "        self.Mixed_6e = InceptionC(768, channels_7x7=192)\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = InceptionAux(768, num_classes)\n",
    "        self.Mixed_7a = InceptionD(768)\n",
    "        self.Mixed_7b = InceptionE(1280)\n",
    "        self.Mixed_7c = InceptionE(2048)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "#                 import scipy.stats as stats\n",
    "#                 stddev = m.stddev if hasattr(m, 'stddev') else 0.1\n",
    "#                 X = stats.truncnorm(-2, 2, scale=stddev)\n",
    "#                 values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n",
    "#                 values = values.view(m.weight.size())\n",
    "#                 with torch.no_grad():\n",
    "#                     m.weight.copy_(values)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        \n",
    "        ## CIFAR10\n",
    "        # N x 32 x 149 x 149\n",
    "#         x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "#         x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        # N x 64 x 73 x 73\n",
    "#         x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "#         x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "#         x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        if self.training and self.aux_logits:\n",
    "            aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # N x 2048\n",
    "        x = self.fc(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        if self.training and self.aux_logits:\n",
    "            return _InceptionOuputs(x, aux)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = BasicConv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionB, self).__init__()\n",
    "        self.branch3x3 = BasicConv2d(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = BasicConv2d(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, channels_7x7):\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = BasicConv2d(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = BasicConv2d(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionD, self).__init__()\n",
    "        self.branch3x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = BasicConv2d(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = BasicConv2d(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = BasicConv2d(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionE, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = BasicConv2d(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = BasicConv2d(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = BasicConv2d(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(InceptionAux, self).__init__()\n",
    "        self.conv0 = BasicConv2d(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = BasicConv2d(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.fc.stddev = 0.001\n",
    "\n",
    "    def forward(self, x):\n",
    "        # N x 768 x 17 x 17\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # N x 768 x 5 x 5\n",
    "        x = self.conv0(x)\n",
    "        # N x 128 x 5 x 5\n",
    "        x = self.conv1(x)\n",
    "        # N x 768 x 1 x 1\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 768 x 1 x 1\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # N x 768\n",
    "        x = self.fc(x)\n",
    "        # N x 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
